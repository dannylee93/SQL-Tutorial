# 성능 데이터 모델링

 데이터 모델링을 할 때 어떤 작업 유형에 따라 성능 향상을 도모해야 하는지 목표를 분명하게 해야 정확한 성능향상 모델링을 할 수 있다. 
 그래서, 성능 데이터 모델링이란 데이터 베이스의 성능향상을 목적으로 설계단계 때 부터 `정규화, 반정규화, 테이블 통합/분할, 조인구조` 등 여러가지 성능과 관련된 사항이 반영 되어야한다.



### 고려사항
1. 정규화를 정확하게 수행
2. 용량 산정
3. 트랜잭션 유형 파악
4. 용량/트랜잭션 유행 에 따라 반정규화 수행
5. 이력모델의 조정, PK/FK조정, 슈퍼타입/서브타입 조정 등을 수행
6. 성능관점에서 모델 검증해보기

### 카테고리

1. 정규화와 반정규화
2. **대량 데이터**와 성능
3. 데이터베이스의 **구조**와 성능
4. **분산** 데이터베이스와 성능

## 정규화 Normalization

데이터를 모델링 하면서 정규화를 하는 이유는 기본적으로 데이터에 대한 중복성을 제거하고, 관심사별로 처리되는 경우가 많아 성능이 향상되는 특징을 가진다. 

정규화를 하면 엔터티가 계속 발생된다는 단점이 있지만 일부 부분은 유의하여 따로 반정규화를 적절히 적용하는 전략도 중요하다.

정규화를 수행한다는 말은 속성의`입력 이상`, `수정 이상`, `삭제 이상` 이 3가지를 제거 하는 것이다.

| 이상 현상 |                       내 용                        |
| :-------: | :------------------------------------------------: |
| 입력 이상 | 데이터 입력 시 필요없는 속성까지 입력해야하는 현상 |
| 수정 이상 |   수정 시 원하지 않는 데이터 까지 수정되는 현상    |
| 삭제 이상 |      삭제시 필요한 데이터 까지 삭제되는 현상       |



### 정규화 종류

|    정규화 종류     |                             내용                             |   함수 종속성   |
| :----------------: | :----------------------------------------------------------: | :-------------: |
|     1차 정규화     | 모든 속성은 원자값을 가지는데, 복수의 속성값을 갖는 속성을 분리 |                 |
|     2차 정규화     | 주 식별자에 종속적이지 않은 속성 분리(부분 종속되는 속성을 분리) |  부분함수속성   |
|     3차 정규화     |      속성에 종속적인 속성의 분리(이전 종속 속성의 분리)      | 이행함수 종속성 |
| 보이스-코드 정규화 |                     다수의 주식별자 분리                     |                 |
|     4차 정규화     |                   속성간의 다중종속성 제거                   |   다중 종속성   |
|     5차 정규화     |                       Join 종속성 제거                       |   Join 종속성   |



#### 1차 정규화

![](http://tech.devgear.co.kr/files/attach/images/271/333/676c874a59da8f049938d33feacc12fc.png)

> 위 이미지는 하나의 제품에 대해 여러개의 주문서가 접수된 내용이다.

위의 현상으로 인해 아래의 **3가지 이상 현상**을 볼 수 있다.

- `입력 이상` : 주문이 발생되어야만 제품 정보를 등록할 수 있다.
- `수정 이상` : 마우스의 수량을 9702에서 15000으로 변경하고자 한다면 데이터를 3번 수정해야 한다.
- `삭제 이상` : 제품번호가 1201인 스피커를 주문한 내역을 삭제하면 제품명, 재고수량 정보도 모두 삭제된다.

여기서 **1차 정규화**는 이러한 반복되어 생성되는 주문 관련 정보를 분리하면서 수행한다.

![](http://tech.devgear.co.kr/files/attach/images/271/333/f48fea19eda0f5e7cfe947a401238215.png)

> 변하지 않은 제품이라는 주 엔터티와 , 계속 변경되는 주문 목록을 별도의 엔터티로 구분했다.



#### 2차 정규화

사전적 의미로는, 복합식별자로 구성된 경우 엔터티 안의 속성들은 복합 식별자 전체에 의존적이어야 하는데, 만약 복합식별자 일부에 의존적 속성이 있다면 이것을 제거해야한다.

즉, 2개 이상의 열의 값에 따라오는 값이랑 그 외의 하나의 열의 값에 따라오는 속성이랑 엔터티 나누자는 말이다.

1. *제품번호 + 주문번호에 종속적인 속성 : 주문수량*

2. *주문번호에 종속적인 속성 : 수출여부, 고객번호, 사업자번호, 우선순위*
   - `입력 이상` : 고객정보 입력 시 주문정보도 입력해야 함
   - `수정 이상` : 만약 주문번호 AB345의 우선순위를 1에서 10으로 수정할 경우, 1001+AB345와 1007+AB345를 같이 수정해야 함
   - `삭제 이상` : 주문번호 삭제시 고객번호도 함께 삭제됨 

![](http://tech.devgear.co.kr/files/attach/images/271/333/2be26ddcb6edc7e6d7f6a22dc7a48d8e.png)

> [제품번호+주문번호]에 따르는 열과 [주문번호]에 따르는 열을 나눴다.



#### 3차 정규화

위와 같이 2차 정규화 된 상태에서 설명하자면, 아래의 이상현상이 생긴다.

- `입력 이상` : 새로운 고객 등록 시 주문이 없으면 입력이 안됨
- `수정 이상` : 한 고객이 여러 번 주문한 경우 고객 정보가 반복적으로 발생. 고객 정보 수정시 여러 개의 데이터를 수정해야 한다.
- `삭제 이상` : 고객번호 4520이 주문을 취소하면 주문 정보만 삭제되는 것이 아니라 고객 정보도 모두 삭제된다. 

[주문] 이라는 열에 따라 고객에 대한 데이터가 계속 종속적으로 바뀐다면 분리 해줘야 한다.

![](http://tech.devgear.co.kr/files/attach/images/271/333/3907dfaf0afecddb4606cf6cf8e6f35a.png)



## 반정규화 De-Normalization

> 역 정규화라고도 하는데, 데이터의 정합성과 무결성을 우선으로 할지 <> 데이터베이스의 구성 단순화와 성능 우선으로 할지 결정하는 것이다.

일부 부분에 반정규화를 하는 이유는 데이터를 조회할 때 양이 너무 많이 성능이 저하되거나 경로가 너무 멀어져 조인으로 인한 성능저하가 예상되거나 할 때 반정규화를 수행한다.



### 반정규화 절차

![](http://www.dbguide.net/publishing/img/knowledge/SQL_090.jpg)

1. **반정규화 대상 조사**
   - 범위 처리 빈도수 조사 : 자주 사용되는 테이블에 접근하는 프로세스 수가 많고, 항상 일정한 범위만을 조회하는 경우
   - 대량의 범위 처리 조사 : 대량이 데이터 범위를 자주 처리하는 경우
   - 통계성 프로세스 조사 : 별도의 통계 테이블 고려
   - 테이블 조인 개수 : 지나치게 많은 조인이 걸려 데이터 조회 작업이 어려운 경우
2. **다른 방법 유도 검토**
   - 뷰 테이블 : 지나치게 많은 조인이 걸려 데이터 조회하는 작업이 어려운 경우
   - 클러스터링 또는 인덱스 적용 : 대량의 데이터는 PK의 성격에 따라 부분적인 테이블로 분리할 수 있다.(파티셔닝 기법)
   - 애플리케이션 : 로직을 변경함으로써 성능을 향상시킬 수 있다. 
3. **반정규화(역정규화) 적용**
   -  테이블 반정규화
   - 속성의 반정규화
   - 관계의 반정규화



### 반정규화 방법

1. 테이블 반정규화

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_091.jpg)

2. 칼럼 반정규화

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_092.jpg)

3. 관계 반정규화

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_093.jpg)



## 대량의 데이터와 성능의 관계

아무리 설계 잘해놔도 대량의 데이터라면 말이 달라진다. 고속도로 차선 넓혀도 막히는 느낌

트랜잭션이 분산처리될 수 있도록 테이블 단위에서 분할의 방법을 적용할 필요 있다.

![](http://www.dbguide.net/publishing/img/knowledge/SQL_103.jpg)

1. 수평 분할 : 칼럼(열)단위 분할
2. 수직 분할 : 로우(행)단위 분할

대량이 데이터가 성능이 저하되는 이유는 많은 사람이 하나의 데이터에서 SQL문장을 쓰니까 그걸 처리하려고 하는 I/O의 양이 증가하기 때문이다.

프로젝트를 수행할 때 때로는 하나의 테이블에 300개 이상의 칼럼을 가지고 있는 경우가 있다. 컴퓨터 화면 하나에는 볼 수가 없어서 스크롤을 하면서 하나의 테이블에 있는 칼럼을 구경해야 할 정도이다. 이렇게 많은 칼럼은 로우체이닝과 로우마이그레이션이 많아지게 되어 성능이 저하된다.

- `로우체이닝(Row Chaining)` : 로우 길이가 너무 길어서 데이터 블록 하나에 데이터가 모두 저장되지 않고 두 개 이상의 블록에 걸쳐 하나의 로우가 저장되어 있는 형태
- `로우마이그레이션(Row Migration)` : 데이터 블록에서 수정이 발생하면 수정된 데이터를 해당 데이터 블록에서 저장하지 못하고 다른 블록의 빈 공간을 찾아 저장하는 방식



#### 한 테이블에 많은 수 의 칼럼 있는 경우?

아래 이미지 처럼 [도서정보]라는 엔터티 안에 약 200개의 칼럼이 있다. 이걸 하나에 다 저장하면? 많은 I/O가 일어나는 것이다.

이럴 때, 트랜잭션이 어떤 칼럼에 대해 집중적으로 발생하는지 분석한 후 그 인사이트에 맞게 테이블을 쪼개 주면 I/O양이 감소하면서 성능개선을 노릴 수 있다.

![](http://www.dbguide.net/publishing/img/knowledge/SQL_106.jpg)

#### 대량 데이터 저장/처리 와 성능

이번에는 테이블에 **많은 양의 데이터(행)**가 있는 경우다. 이 때는 **파티셔닝**을 적용하거나 **PK**에 의해 테이블을 분할하는 방법을 적용할 수 있다.

1. *RANGE PARTITION (범위)*
2. *LIST PARTITION (특정값 지정)*
3. *HASH PARTITION (해쉬)*



##### RANGE PARTITION (범위)

패턴이 보이는 하나의 범위를 선정해서 나누는 방법이다. 아래 예시는 요금 데이터를 연+월로 산정하는 것이다.

![](http://www.dbguide.net/publishing/img/knowledge/SQL_108.jpg)

##### LIST PARTITION (특정값 지정)

예를 들어, 아래 이미지 처럼 고객의 데이터가 1억건 있는데 이걸 사업소 코드별로 지역을 새로 묶은걸로 들 수 있다.

![](http://www.dbguide.net/publishing/img/knowledge/SQL_109.jpg)

##### HASH PARTITION

HASH 조건에 따라 해슁 알고리즘이 적용되어 테이블이 분리되며 설계자는 테이블에 데이터가 정확하게 어떻게 들어갔는지 알 수 없다.



## 데이터의 구조와 성능

1. 슈퍼타입, 서브타입 모델의 성능고려 방법
2. 인덱스 특성을 고려한 PK/FK 데이터베이스 성능향상
3. 물리적인 테이블에 FK제약이 걸려있지 않을 경우 인덱스 미생성으로 성능저하



### 슈퍼타입, 서브타입 모델의 성능고려 방법

Extended ER모델이라고 부르는 이 모델은, 공통의 부분은 슈퍼타입으로 모델링하고 공통으로 상속 받아 다른 엔터티와 차이 있는 속성은 별도로 서브엔터티로 구분하는 모델 변환 방법.

변환하는 기준은 **데이터 양**과 해당 테이블에 발생되는 **트랜잭션의 유형**에 따라 결정된다.



#### 변환 기술

1. 개별로 발생되는 트랜잭션은 개별 테이블로 구성:

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_112.jpg)

   위 이미지 처럼 슈퍼타입과 서브타입 각각 독립적인 트랜잭션 발생 되면, 각각 필요한 속성만들 가지게 1:1 관계 갖게 해야한다.

2. 슈퍼타입+서브타입에 대해 발생되는 트랜잭션에 대해서는 **슈퍼타입+서브타입 테이블**로 구성

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_113.jpg)

   만약 위와같이 기본적으로 [당사자명~전화번호] 까지 슈퍼타입과 함께 아래 3가지 서브타입이 모두 필요한 테이블이 있는데 여기서 만약 이해관계인은 10만건, 대리인/매수인은 각각 500만건이면 이 테이블 조회할 때마다 약 천만건을 뒤져봐야한다.

   그래서 아래 화살표 처럼 슈퍼/서브 테이블을 합치고 나눠서 새로운 3개의 테이블을 만들었다.

3. 전체를 하나로 묶어 트랜잭션이 발생할 때는 하나의 테이블로 구성

   수 많은 데이터가 있어서 성능 저하가 된다고 예상해도, 그 반면에 위와 같이 3개로 나눴을 때도  불필요한 UNION ALL과 같은 SQL구문이 작성되어 성능이 저하될 수도 있다.



### 인덱스 특성을 고려한 PK/FK 데이터베이스 성능향상

1. PK/FK 칼럼 순서와 성능개요

   데이터를 조회할 때 가장 효과적으로 처리될 수 있도록 접근경로를 제공하는 오브젝트가 바로 인덱스이다. 이 중요한 칼럼의 순서도 성능에 영향을 미친다.

2. PK칼럼의 순서를 조정하지 않으면 성능이 저하 이유

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_117.jpg)

   위 처럼 주분 번호에 의해 조회되면 첫번 째 칼럼에 의해 비교되는 것이기 때문에 순차적으로 찾아간다. 만약 이 맨 앞의 칼럼이 제외된 상태에서 데이터를 조회하면 비교 범위가 넓어져서 성능저하 온다.

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_118.jpg)

   위에서 말한것 처럼 맨 앞에 잘 정리된 인덱스로 조회하지 않았다면? 인덱스 전체를 읽어야 원하는 데이터를 뽑아낼 수 있다(빨간색 화살표 비교)

3. PK순서를 잘못 지정하여 성능이 저하된 경우 - 간단한 오류, 복잡한 오류

   간단한 오류는 SQL 문의 순서와 관련된 문제이다. 복잡한 오류는 조회량과 관련하여 PK순서를 지정하지 않았을 때다.

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_123.jpg)

   위에 문제를 보면 인덱스 순서대로 최적화 되었다고 보여진다. 하지만?

   ![](http://www.dbguide.net/publishing/img/knowledge/SQL_124.jpg)

   겉에 보이는 순서대로만 지정했을 때는 인덱스를 훨씬 많이 조회해야하는데 두 인덱스를 역으로 순서를 바꿔 조회하면 훨씬 더 효율이 좋은 것을 볼 수 있다(이건 상황에 따라 달라지는 거다.)



### 물리적인 테이블에 FK제약이 걸려있지 않을 경우 인덱스 미생성으로 성능저하

![](http://www.dbguide.net/publishing/img/knowledge/SQL_125.jpg)

예를 들어, 위처럼 [학사기준] (5만개)과 [수강신청] (500만개)테이블이 있는데 WHERE 절과 맨 아래 빨간색을 해석하자면 FK 인덱스를 생성하지 않아서 테이블 전체를 봤다는 말이다.

![](http://www.dbguide.net/publishing/img/knowledge/SQL_127.jpg)

여기서 중간에 CREATE를 보면 새로 [수강신청] 테이블의 FK를 생성했더니 맨 아래에서 Range scan으로 변경됨을 볼 수 있다.

